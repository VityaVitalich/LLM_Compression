{
  "results": {
    "ai2_arc": {
      "acc,none": 0.6600901916572717,
      "acc_stderr,none": 0.046017959748512194,
      "acc_norm,none": 0.6547350620067643,
      "acc_norm_stderr,none": 0.040259797678463834,
      "alias": "ai2_arc"
    },
    "arc_challenge": {
      "acc,none": 0.46757679180887374,
      "acc_stderr,none": 0.014580637569995414,
      "acc_norm,none": 0.4880546075085324,
      "acc_norm_stderr,none": 0.014607220340597171,
      "alias": " - arc_challenge"
    },
    "arc_easy": {
      "acc,none": 0.7550505050505051,
      "acc_stderr,none": 0.008824588611219089,
      "acc_norm,none": 0.7369528619528619,
      "acc_norm_stderr,none": 0.009034514898865826,
      "alias": " - arc_easy"
    },
    "boolq": {
      "acc,none": 0.7929663608562691,
      "acc_stderr,none": 0.007086640139257138,
      "alias": "boolq"
    },
    "hellaswag": {
      "acc,none": 0.6110336586337383,
      "acc_stderr,none": 0.004865193237024039,
      "acc_norm,none": 0.7924716191993627,
      "acc_norm_stderr,none": 0.0040470831200988665,
      "alias": "hellaswag"
    },
    "piqa": {
      "acc,none": 0.7611534276387377,
      "acc_stderr,none": 0.009948120385337498,
      "acc_norm,none": 0.7899891186071817,
      "acc_norm_stderr,none": 0.00950335330581856,
      "alias": "piqa"
    },
    "winogrande": {
      "acc,none": 0.6661404893449092,
      "acc_stderr,none": 0.013254029695143341,
      "alias": "winogrande"
    }
  },
  "groups": {
    "ai2_arc": {
      "acc,none": 0.6600901916572717,
      "acc_stderr,none": 0.046017959748512194,
      "acc_norm,none": 0.6547350620067643,
      "acc_norm_stderr,none": 0.040259797678463834,
      "alias": "ai2_arc"
    }
  },
  "configs": {
    "arc_challenge": {
      "task": "arc_challenge",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Challenge",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "arc_easy": {
      "task": "arc_easy",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Easy",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "boolq": {
      "task": "boolq",
      "group": [
        "super-glue-lm-eval-v1"
      ],
      "dataset_path": "super_glue",
      "dataset_name": "boolq",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "{{passage}}\nQuestion: {{question}}?\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": [
        "no",
        "yes"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc"
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "passage",
      "metadata": [
        {
          "version": 2.0
        }
      ]
    },
    "hellaswag": {
      "task": "hellaswag",
      "group": [
        "multiple_choice"
      ],
      "dataset_path": "hellaswag",
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "<function process_docs at 0x155482a9f640>",
      "doc_to_text": "{{query}}",
      "doc_to_target": "{{label}}",
      "doc_to_choice": "choices",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "piqa": {
      "task": "piqa",
      "dataset_path": "piqa",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "Question: {{goal}}\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": "{{[sol1, sol2]}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "goal",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "winogrande": {
      "task": "winogrande",
      "dataset_path": "winogrande",
      "dataset_name": "winogrande_xl",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x1554828a5510>",
      "doc_to_target": "<function doc_to_target at 0x1554828a5ab0>",
      "doc_to_choice": "<function doc_to_choice at 0x1554828a5e10>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "sentence",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    }
  },
  "versions": {
    "ai2_arc": "N/A",
    "arc_challenge": "Yaml",
    "arc_easy": "Yaml",
    "boolq": "Yaml",
    "hellaswag": "Yaml",
    "piqa": "Yaml",
    "winogrande": "Yaml"
  },
  "n-shot": {
    "ai2_arc": 0,
    "arc_challenge": 0,
    "arc_easy": 0,
    "boolq": 0,
    "hellaswag": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/home/LLM_Compression/logs/fine_tuning/full/Llama7b_ste_lima_4bit/checkpoint-242,parallelize=True",
    "batch_size": "16",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": {}
  },
  "git_hash": "bd242b2"
}