{
  "results": {
    "ai2_arc": {
      "acc,none": 0.6801014656144306,
      "acc_stderr,none": 0.04799282602305033,
      "acc_norm,none": 0.6744644870349493,
      "acc_norm_stderr,none": 0.042149242444176525,
      "alias": "ai2_arc"
    },
    "arc_challenge": {
      "acc,none": 0.4786689419795222,
      "acc_stderr,none": 0.014598087973127108,
      "acc_norm,none": 0.4991467576791809,
      "acc_norm_stderr,none": 0.014611369529813272,
      "alias": " - arc_challenge"
    },
    "arc_easy": {
      "acc,none": 0.7794612794612794,
      "acc_stderr,none": 0.008507616235669015,
      "acc_norm,none": 0.7609427609427609,
      "acc_norm_stderr,none": 0.008751754723580425,
      "alias": " - arc_easy"
    },
    "boolq": {
      "acc,none": 0.789908256880734,
      "acc_stderr,none": 0.0071250080386654575,
      "alias": "boolq"
    },
    "hellaswag": {
      "acc,none": 0.6150169288986258,
      "acc_stderr,none": 0.0048559685789986975,
      "acc_norm,none": 0.8041226847241585,
      "acc_norm_stderr,none": 0.0039606343058642066,
      "alias": "hellaswag"
    },
    "piqa": {
      "acc,none": 0.7889009793253536,
      "acc_stderr,none": 0.009521377378734158,
      "acc_norm,none": 0.7981501632208923,
      "acc_norm_stderr,none": 0.009364873741341448,
      "alias": "piqa"
    },
    "winogrande": {
      "acc,none": 0.6858721389108129,
      "acc_stderr,none": 0.013045416716072566,
      "alias": "winogrande"
    }
  },
  "groups": {
    "ai2_arc": {
      "acc,none": 0.6801014656144306,
      "acc_stderr,none": 0.04799282602305033,
      "acc_norm,none": 0.6744644870349493,
      "acc_norm_stderr,none": 0.042149242444176525,
      "alias": "ai2_arc"
    }
  },
  "configs": {
    "arc_challenge": {
      "task": "arc_challenge",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Challenge",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "arc_easy": {
      "task": "arc_easy",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Easy",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "boolq": {
      "task": "boolq",
      "group": [
        "super-glue-lm-eval-v1"
      ],
      "dataset_path": "super_glue",
      "dataset_name": "boolq",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "{{passage}}\nQuestion: {{question}}?\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": [
        "no",
        "yes"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc"
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "passage",
      "metadata": [
        {
          "version": 2.0
        }
      ]
    },
    "hellaswag": {
      "task": "hellaswag",
      "group": [
        "multiple_choice"
      ],
      "dataset_path": "hellaswag",
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "<function process_docs at 0x155482a9f6d0>",
      "doc_to_text": "{{query}}",
      "doc_to_target": "{{label}}",
      "doc_to_choice": "choices",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "piqa": {
      "task": "piqa",
      "dataset_path": "piqa",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "Question: {{goal}}\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": "{{[sol1, sol2]}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "goal",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "winogrande": {
      "task": "winogrande",
      "dataset_path": "winogrande",
      "dataset_name": "winogrande_xl",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x1554828a55a0>",
      "doc_to_target": "<function doc_to_target at 0x1554828a5b40>",
      "doc_to_choice": "<function doc_to_choice at 0x1554828a5ea0>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "sentence",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    }
  },
  "versions": {
    "ai2_arc": "N/A",
    "arc_challenge": "Yaml",
    "arc_easy": "Yaml",
    "boolq": "Yaml",
    "hellaswag": "Yaml",
    "piqa": "Yaml",
    "winogrande": "Yaml"
  },
  "n-shot": {
    "ai2_arc": 0,
    "arc_challenge": 0,
    "arc_easy": 0,
    "boolq": 0,
    "hellaswag": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/home/LLM_Compression/logs/fine_tuning/full/Llama7b_ste_lima_4bit_teach-tulu70-dpo/checkpoint-229",
    "batch_size": "16",
    "batch_sizes": [],
    "device": "cuda:0",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": {}
  },
  "git_hash": "b6e1e1c"
}