{
  "results": {
    "ai2_arc": {
      "acc,none": 0.7153325817361894,
      "acc_stderr,none": 0.044915929829741096,
      "acc_norm,none": 0.7074408117249155,
      "acc_norm_stderr,none": 0.039543862382675404,
      "alias": "ai2_arc"
    },
    "arc_challenge": {
      "acc,none": 0.5273037542662116,
      "acc_stderr,none": 0.014589589101985993,
      "acc_norm,none": 0.5435153583617748,
      "acc_norm_stderr,none": 0.014555949760496435,
      "alias": " - arc_challenge"
    },
    "arc_easy": {
      "acc,none": 0.8080808080808081,
      "acc_stderr,none": 0.008080808080807954,
      "acc_norm,none": 0.7882996632996633,
      "acc_norm_stderr,none": 0.008382520764977718,
      "alias": " - arc_easy"
    },
    "boolq": {
      "acc,none": 0.8107033639143731,
      "acc_stderr,none": 0.006851646930700859,
      "alias": "boolq"
    },
    "hellaswag": {
      "acc,none": 0.6411073491336388,
      "acc_stderr,none": 0.00478695314665705,
      "acc_norm,none": 0.8271260705038836,
      "acc_norm_stderr,none": 0.0037736543936860364,
      "alias": "hellaswag"
    },
    "piqa": {
      "acc,none": 0.7910772578890098,
      "acc_stderr,none": 0.009485227030105061,
      "acc_norm,none": 0.8122959738846572,
      "acc_norm_stderr,none": 0.009110440292132567,
      "alias": "piqa"
    },
    "winogrande": {
      "acc,none": 0.712707182320442,
      "acc_stderr,none": 0.012717481052478033,
      "alias": "winogrande"
    }
  },
  "groups": {
    "ai2_arc": {
      "acc,none": 0.7153325817361894,
      "acc_stderr,none": 0.044915929829741096,
      "acc_norm,none": 0.7074408117249155,
      "acc_norm_stderr,none": 0.039543862382675404,
      "alias": "ai2_arc"
    }
  },
  "configs": {
    "arc_challenge": {
      "task": "arc_challenge",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Challenge",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "arc_easy": {
      "task": "arc_easy",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Easy",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "boolq": {
      "task": "boolq",
      "group": [
        "super-glue-lm-eval-v1"
      ],
      "dataset_path": "super_glue",
      "dataset_name": "boolq",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "{{passage}}\nQuestion: {{question}}?\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": [
        "no",
        "yes"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc"
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "passage",
      "metadata": [
        {
          "version": 2.0
        }
      ]
    },
    "hellaswag": {
      "task": "hellaswag",
      "group": [
        "multiple_choice"
      ],
      "dataset_path": "hellaswag",
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "<function process_docs at 0x155482a9f640>",
      "doc_to_text": "{{query}}",
      "doc_to_target": "{{label}}",
      "doc_to_choice": "choices",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "piqa": {
      "task": "piqa",
      "dataset_path": "piqa",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "Question: {{goal}}\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": "{{[sol1, sol2]}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "goal",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "winogrande": {
      "task": "winogrande",
      "dataset_path": "winogrande",
      "dataset_name": "winogrande_xl",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x1554828a5510>",
      "doc_to_target": "<function doc_to_target at 0x1554828a5ab0>",
      "doc_to_choice": "<function doc_to_choice at 0x1554828a5e10>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "sentence",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    }
  },
  "versions": {
    "ai2_arc": "N/A",
    "arc_challenge": "Yaml",
    "arc_easy": "Yaml",
    "boolq": "Yaml",
    "hellaswag": "Yaml",
    "piqa": "Yaml",
    "winogrande": "Yaml"
  },
  "n-shot": {
    "ai2_arc": 0,
    "arc_challenge": 0,
    "arc_easy": 0,
    "boolq": 0,
    "hellaswag": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/home/LLM_Compression/logs/fine_tuning/full/Llama13b_lima/checkpoint-242,parallelize=True",
    "batch_size": "16",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": {}
  },
  "git_hash": "b6e1e1c"
}