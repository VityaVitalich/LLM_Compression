{
  "results": {
    "ai2_arc": {
      "acc,none": 0.45377677564825253,
      "acc_stderr,none": 0.03328591266449504,
      "acc_norm,none": 0.4467305524239008,
      "acc_norm_stderr,none": 0.024087694388143926,
      "alias": "ai2_arc"
    },
    "arc_challenge": {
      "acc,none": 0.3191126279863481,
      "acc_stderr,none": 0.013621696119173302,
      "acc_norm,none": 0.35580204778157,
      "acc_norm_stderr,none": 0.013990571137918757,
      "alias": " - arc_challenge"
    },
    "arc_easy": {
      "acc,none": 0.5202020202020202,
      "acc_stderr,none": 0.010251405621305368,
      "acc_norm,none": 0.49158249158249157,
      "acc_norm_stderr,none": 0.010258329515226454,
      "alias": " - arc_easy"
    },
    "boolq": {
      "acc,none": 0.6434250764525994,
      "acc_stderr,none": 0.008377548099415487,
      "alias": "boolq"
    },
    "hellaswag": {
      "acc,none": 0.5571599283011353,
      "acc_stderr,none": 0.004957068377516497,
      "acc_norm,none": 0.7302330213104959,
      "acc_norm_stderr,none": 0.0044293157883104235,
      "alias": "hellaswag"
    },
    "piqa": {
      "acc,none": 0.719260065288357,
      "acc_stderr,none": 0.010484325438311827,
      "acc_norm,none": 0.7263329706202394,
      "acc_norm_stderr,none": 0.010402184206229213,
      "alias": "piqa"
    },
    "winogrande": {
      "acc,none": 0.6519337016574586,
      "acc_stderr,none": 0.013388004531086054,
      "alias": "winogrande"
    }
  },
  "groups": {
    "ai2_arc": {
      "acc,none": 0.45377677564825253,
      "acc_stderr,none": 0.03328591266449504,
      "acc_norm,none": 0.4467305524239008,
      "acc_norm_stderr,none": 0.024087694388143926,
      "alias": "ai2_arc"
    }
  },
  "configs": {
    "arc_challenge": {
      "task": "arc_challenge",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Challenge",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "arc_easy": {
      "task": "arc_easy",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Easy",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "boolq": {
      "task": "boolq",
      "group": [
        "super-glue-lm-eval-v1"
      ],
      "dataset_path": "super_glue",
      "dataset_name": "boolq",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "{{passage}}\nQuestion: {{question}}?\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": [
        "no",
        "yes"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc"
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "passage",
      "metadata": [
        {
          "version": 2.0
        }
      ]
    },
    "hellaswag": {
      "task": "hellaswag",
      "group": [
        "multiple_choice"
      ],
      "dataset_path": "hellaswag",
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "<function process_docs at 0x155482a9f640>",
      "doc_to_text": "{{query}}",
      "doc_to_target": "{{label}}",
      "doc_to_choice": "choices",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "piqa": {
      "task": "piqa",
      "dataset_path": "piqa",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "Question: {{goal}}\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": "{{[sol1, sol2]}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "goal",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "winogrande": {
      "task": "winogrande",
      "dataset_path": "winogrande",
      "dataset_name": "winogrande_xl",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x1554828a1510>",
      "doc_to_target": "<function doc_to_target at 0x1554828a1ab0>",
      "doc_to_choice": "<function doc_to_choice at 0x1554828a1e10>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "sentence",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    }
  },
  "versions": {
    "ai2_arc": "N/A",
    "arc_challenge": "Yaml",
    "arc_easy": "Yaml",
    "boolq": "Yaml",
    "hellaswag": "Yaml",
    "piqa": "Yaml",
    "winogrande": "Yaml"
  },
  "n-shot": {
    "ai2_arc": 0,
    "arc_challenge": 0,
    "arc_easy": 0,
    "boolq": 0,
    "hellaswag": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/home/LLM_Compression/logs/fine_tuning/full/Llama7b_lima_quik_4bit_lora/checkpoint-121,parallelize=True",
    "batch_size": "16",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": {}
  },
  "git_hash": "00579e2"
}