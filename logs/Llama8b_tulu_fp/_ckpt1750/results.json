{
  "results": {
    "ai2_arc": {
      "acc,none": 0.7240698985343855,
      "acc_stderr,none": 0.046670752104535855,
      "acc_norm,none": 0.7316798196166855,
      "acc_norm_stderr,none": 0.0429943812873535,
      "alias": "ai2_arc"
    },
    "arc_challenge": {
      "acc,none": 0.5281569965870307,
      "acc_stderr,none": 0.014588204105102203,
      "acc_norm,none": 0.5520477815699659,
      "acc_norm_stderr,none": 0.014532011498211678,
      "alias": " - arc_challenge"
    },
    "arc_easy": {
      "acc,none": 0.8207070707070707,
      "acc_stderr,none": 0.007871252820726031,
      "acc_norm,none": 0.8202861952861953,
      "acc_norm_stderr,none": 0.007878465068489264,
      "alias": " - arc_easy"
    },
    "boolq": {
      "acc,none": 0.8403669724770643,
      "acc_stderr,none": 0.006406021659710517,
      "alias": "boolq"
    },
    "hellaswag": {
      "acc,none": 0.6042620991834295,
      "acc_stderr,none": 0.004880092083408046,
      "acc_norm,none": 0.7943636725751843,
      "acc_norm_stderr,none": 0.004033398416396052,
      "alias": "hellaswag"
    },
    "piqa": {
      "acc,none": 0.8003264417845484,
      "acc_stderr,none": 0.009326942154519176,
      "acc_norm,none": 0.8133841131664853,
      "acc_norm_stderr,none": 0.009090077190470804,
      "alias": "piqa"
    },
    "winogrande": {
      "acc,none": 0.7419100236779794,
      "acc_stderr,none": 0.01229827883397239,
      "alias": "winogrande"
    }
  },
  "groups": {
    "ai2_arc": {
      "acc,none": 0.7240698985343855,
      "acc_stderr,none": 0.046670752104535855,
      "acc_norm,none": 0.7316798196166855,
      "acc_norm_stderr,none": 0.0429943812873535,
      "alias": "ai2_arc"
    }
  },
  "configs": {
    "arc_challenge": {
      "task": "arc_challenge",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Challenge",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "arc_easy": {
      "task": "arc_easy",
      "group": [
        "ai2_arc"
      ],
      "dataset_path": "ai2_arc",
      "dataset_name": "ARC-Easy",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{question}}\nAnswer:",
      "doc_to_target": "{{choices.label.index(answerKey)}}",
      "doc_to_choice": "{{choices.text}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "boolq": {
      "task": "boolq",
      "group": [
        "super-glue-lm-eval-v1"
      ],
      "dataset_path": "super_glue",
      "dataset_name": "boolq",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "{{passage}}\nQuestion: {{question}}?\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": [
        "no",
        "yes"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc"
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "passage",
      "metadata": [
        {
          "version": 2.0
        }
      ]
    },
    "hellaswag": {
      "task": "hellaswag",
      "group": [
        "multiple_choice"
      ],
      "dataset_path": "hellaswag",
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "<function process_docs at 0x155482a9f760>",
      "doc_to_text": "{{query}}",
      "doc_to_target": "{{label}}",
      "doc_to_choice": "choices",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "piqa": {
      "task": "piqa",
      "dataset_path": "piqa",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "Question: {{goal}}\nAnswer:",
      "doc_to_target": "label",
      "doc_to_choice": "{{[sol1, sol2]}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "goal",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    },
    "winogrande": {
      "task": "winogrande",
      "dataset_path": "winogrande",
      "dataset_name": "winogrande_xl",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "<function doc_to_text at 0x1554828a1630>",
      "doc_to_target": "<function doc_to_target at 0x1554828a1bd0>",
      "doc_to_choice": "<function doc_to_choice at 0x1554828a1f30>",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "sentence",
      "metadata": [
        {
          "version": 1.0
        }
      ]
    }
  },
  "versions": {
    "ai2_arc": "N/A",
    "arc_challenge": "Yaml",
    "arc_easy": "Yaml",
    "boolq": "Yaml",
    "hellaswag": "Yaml",
    "piqa": "Yaml",
    "winogrande": "Yaml"
  },
  "n-shot": {
    "ai2_arc": 0,
    "arc_challenge": 0,
    "arc_easy": 0,
    "boolq": 0,
    "hellaswag": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/home/LLM_Compression/ckpts/full/Llama8b_tulu_fp/checkpoint-1750,parallelize=True",
    "batch_size": "16",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": {}
  },
  "git_hash": "b586257"
}