{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:521: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sparseml.transformers import SparseAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    LlamaTokenizer,\n",
    "    LlamaTokenizerFast,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"/home/exp_results/output_llama7b_sparseml/stage_sparsity\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.model.layers[0].self_attn.q_proj.weight.data\n",
    "mask = (w == 0.0)\n",
    "mask.sum() / mask.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparseml.transformers.sparsification import Trainer, TrainingArguments\n",
    "from transformers import default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Chunks for recipe.md: 100%|██████████| 3.47k/3.47k [00:01<00:00, 3.35kB/s]\n",
      "Combining Chunks: 100%|██████████| 3.47k/3.47k [00:00<00:00, 102kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/LLM_compression/sparseml/transfer_recipe-squad/recipe.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sparsezoo import Model\n",
    "transfer_stub = \"zoo:nlp/question_answering/obert-base/pytorch/huggingface/squad/pruned90_quant-none\"\n",
    "download_dir = \"./transfer_recipe-squad\"\n",
    "zoo_model = Model(transfer_stub, download_path=download_dir)\n",
    "recipe_path = zoo_model.recipes.default.path\n",
    "print(recipe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:521: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "from sparseml.transformers import (\n",
    "    DataTrainingArguments,\n",
    "    SparseAutoModelForCausalLM,\n",
    "    SparseAutoTokenizer,\n",
    "    TextGenerationDataset,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# model_path = \"/home/exp_results/output_llama7b_sparseml/stage_sparsity\"\n",
    "model_path = \"/home/LLaMA/huggingface/Llama-2-7b-hf\"\n",
    "model = SparseAutoModelForCausalLM.from_pretrained(\n",
    "    model_path, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n",
      "2024-06-19 12:57:17 sparseml.transformers.utils.helpers INFO     Found recipe in the model_path: /home/exp_results/output_llama7b_sparseml/stage_pruning/recipe.yaml\n",
      "2024-06-19 12:57:17 sparseml.core.recipe.recipe INFO     Loading recipe from file /home/exp_results/output_llama7b_sparseml/stage_pruning/recipe.yaml\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "manager stage: Model structure initialized\n",
      "2024-06-19 12:57:17 sparseml.pytorch.model_load.helpers INFO     Applied an unstaged recipe to the model at /home/exp_results/output_llama7b_sparseml/stage_pruning\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/exp_results/output_llama7b_sparseml/stage_pruning\"\n",
    "model = SparseAutoModelForCausalLM.from_pretrained(\n",
    "    model_path, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SFTTrainer' from 'sparseml.transformers' (/home/Quantization/sparseml/src/sparseml/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparseml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     DataTrainingArguments,\n\u001b[1;32m      3\u001b[0m     SFTTrainer,\n\u001b[1;32m      4\u001b[0m     SparseAutoModelForCausalLM,\n\u001b[1;32m      5\u001b[0m     SparseAutoTokenizer,\n\u001b[1;32m      6\u001b[0m     TextGenerationDataset,\n\u001b[1;32m      7\u001b[0m     TrainingArguments,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SFTTrainer' from 'sparseml.transformers' (/home/Quantization/sparseml/src/sparseml/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sparseml.transformers import (\n",
    "    DataTrainingArguments,\n",
    "    SFTTrainer,\n",
    "    SparseAutoModelForCausalLM,\n",
    "    SparseAutoTokenizer,\n",
    "    TextGenerationDataset,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparseml.transformers.sparsification import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
