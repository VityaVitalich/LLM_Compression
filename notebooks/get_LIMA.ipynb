{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data = datasets.load_dataset('allenai/tulu-v2-sft-mixture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'id', 'messages'],\n",
       "        num_rows: 326154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'flan_v2',\n",
       " 'id': 'flan_v2_1',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'Q: A.S. Roma, chairman, James Pallotta; James Pallotta, birthPlace, Boston\\nA: James Pallotta, who was born in Boston, is the chairman of A.S. Roma.\\nQ: Egg Harbor Township, New Jersey, isPartOf, Atlantic County, New Jersey\\nA: Egg Harbor Township is a township in Atlantic County, New Jersey, United States.\\nQ: Hypermarcas, type, S.A. (corporation); Hypermarcas, numberOfEmployees, 10252\\nA: Hypermarcas is an S.A. corporation which employs 10,252 people.\\nQ: Singapore, language, English language; Ayam penyet, region, Singapore\\nA:'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'English is one of the languages spoken in Singapore where ayam penyet comes from.'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_data['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reformat new dataset entries\n",
    "def reformat_new_entry(entry):\n",
    "    # Extracting instruction and output\n",
    "    instruction = entry['instruction']\n",
    "    output = entry['output']\n",
    "    \n",
    "    # Create user message\n",
    "    user_message = {\n",
    "        \n",
    "        'content': instruction,\n",
    "        'role': 'user'\n",
    "    }\n",
    "    \n",
    "    # Create assistant message\n",
    "    assistant_message = {\n",
    "        'content': output,\n",
    "        'role': 'assistant'\n",
    "    }\n",
    "    \n",
    "    return {'messages': [user_message, assistant_message]}\n",
    "\n",
    "# Load the new dataset\n",
    "with open('train_hs.json', 'r') as f:\n",
    "    hs = json.load(f)\n",
    "\n",
    "with open('boolq.json', 'r') as f:\n",
    "    boolq = json.load(f)\n",
    "\n",
    "with open('winogrande.json', 'r') as f:\n",
    "    wino = json.load(f)\n",
    "\n",
    "# Reformat the new dataset\n",
    "ref_hs = [reformat_new_entry(entry) for entry in hs]\n",
    "ref_b = [reformat_new_entry(entry) for entry in boolq]\n",
    "ref_w = [reformat_new_entry(entry) for entry in wino]\n",
    "\n",
    "\n",
    "formatted_data = {\n",
    "    'dataset': [],\n",
    "    'id': [],\n",
    "    'messages': []\n",
    "}\n",
    "\n",
    "for i, entry in enumerate(ref_hs):\n",
    "    formatted_data['dataset'].append('HellaSwag')\n",
    "    formatted_data['id'].append(f'HellaSwag_{i}')\n",
    "    formatted_data['messages'].append(entry['messages'])\n",
    "\n",
    "for i, entry in enumerate(ref_b):\n",
    "    formatted_data['dataset'].append('BoolQ')\n",
    "    formatted_data['id'].append(f'BoolQ_{i}')\n",
    "    formatted_data['messages'].append(entry['messages'])\n",
    "\n",
    "for i, entry in enumerate(ref_w):\n",
    "    formatted_data['dataset'].append('WinoGrande')\n",
    "    formatted_data['id'].append(f'WinoGrande_{i}')\n",
    "    formatted_data['messages'].append(entry['messages'])\n",
    "# Create Hugging Face Dataset\n",
    "hf_dataset = datasets.Dataset.from_dict(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'WinoGrande',\n",
       " 'id': 'WinoGrande_63237',\n",
       " 'messages': [{'content': 'Please choose the correct answer to fill in the blank to complete the given sentence: Volleyball was a favorite sport for Kyle but not Justin because _ as was really tall.\\n\\nOption1: Kyle Option2: Justin Answer format: option1/option2',\n",
       "   'role': 'user'},\n",
       "  {'content': 'the correct answer is option1', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['code_alpaca', 'cot', 'flan_v2', 'gpt4_alpaca', 'hard_coded',\n",
       "       'lima', 'oasst1', 'open_orca', 'science.evidence_inference',\n",
       "       'science.qasper_truncated_4000', 'science.scierc_ner',\n",
       "       'science.scierc_relation', 'science.scifact_json',\n",
       "       'science.scitldr_aic', 'sharegpt', 'wizardlm'], dtype='<U29')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(hf_data['train']['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lima = hf_data.filter(lambda example: example[\"dataset\"] in ['lima', 'open_orca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dataset': 'lima',\n",
       "  'id': 'lima_0',\n",
       "  'messages': [{'role': 'user',\n",
       "    'content': 'Can brain cells move? By movement I mean long distance migration (preferably within the brain only).'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The question is relatively broad and one should take into account that the brain not only consists of neurons, but also glial cells (supportive cells) and pre-mitotic neuronal stem cells. Furthermore, as critical fellow-scientists have indicated, developmental stage is very important, as the developing embryonic brain is very different from the adult brain.\\nHowever, after sifting through various publications, the answer to the question is actually remarkably simple: Yes, brain cells migrate.\\nIn  the adult brain glial cells migrate in the brain (KlÃ¤mbt, 2009). Glial cells are involved in a myriad of functions, but a notable example of migrating glial cells are the oligodendrocytes that migrate relative long distances to find their target axons onto which they wrap themselves to form the insulating myelin sheath (Tsai and Miller, 2002).\\nNeuronal stem cells migrate over long distances in response to injury (Imitola et al., 2004) and they migrate from specific stem-cell locations (e.g., hippocampus and subventricular zone) to other regions (Clarke, 2003).\\nPost-mitotic, but non-differentiated neurons have been shown to migrate in the adult brain in fish (Scott et al., 2012), and in mammals and non-human primates as well (Sawada et al., 2011).\\nNot surprisingly, glial cells, stem cells and neurons also migrate during embryonic development. Most notably, post-mitotic neurons destined to fulfill peripheral functions have to migrate over relatively long distances from the neural crest to their target locations (Neuroscience, 2nd ed, Neuronal Migration).'}]},\n",
       " {'dataset': 'HellaSwag',\n",
       "  'id': 'HellaSwag_0',\n",
       "  'messages': [{'content': 'Please choose the correct ending to complete the given sentence: Removing ice from car: Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then\\n\\nEnding1: , the man adds wax to the windshield and cuts it. Ending2: , a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled. Ending3: , the man puts on a christmas coat, knitted with netting. Ending4: , the man continues removing the snow on his car.\\n\\nAnswer format: ending1/ending2/ending3/ending4',\n",
       "    'role': 'user'},\n",
       "   {'content': 'the correct answer is ending4', 'role': 'assistant'}]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lima['train'][0], hf_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "\n",
    "lima_dataset = Dataset.from_dict({'dataset': lima['train']['dataset'], 'id': lima['train']['id'], 'messages': lima['train']['messages']})\n",
    "new_dataset = Dataset.from_dict({'dataset': hf_dataset['dataset'], 'id': hf_dataset['id'], 'messages': hf_dataset['messages']})\n",
    "\n",
    "# Concatenate datasets\n",
    "concatenated_dataset = concatenate_datasets([lima_dataset, new_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = DatasetDict({'train': new_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'id', 'messages'],\n",
       "        num_rows: 112570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38cc98c4001401c9e01566965f17fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3ba45ed087426c8b962a85cd967380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfb8be243ce4567a2cd533398f97d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/113 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_dataset.push_to_hub(\"VityaVitalich/hellaswag_boolq_winogrande\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'lima',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca',\n",
       " 'open_orca']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lima['train']['dataset'][1000:1050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6eecf07ed8647b58bcdd2b6a182784b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/436 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4e7b865a064dbcadf4708be54d8889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6841767f92834e4ab7d2881ccdae0aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_lima = datasets.load_dataset(\"VityaVitalich/LIMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset', 'id', 'messages'],\n",
       "    num_rows: 1018\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_lima['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'lima',\n",
       " 'id': 'lima_1',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'In our computer systems lecture we were introduced to the MIPS processor. It was (re)developed over the course of the term and has in fact been quite easy to understand. It uses a RISC design, that is its elementary commands are regularly encoded and there are only few of them in order to keep the wires simple.\\nIt was mentioned that CISC follows a different philosophy. I looked briefly at the x86 instruction set and was shocked. I can not image how anyone would want to build a processor that uses so complex a command set!\\nSo I figure there have to be good arguments why large portions of the processor market use CISC architectures. What are they? '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"There is a general historical trend.\\nIn the olden days, memories were small, and so programs were perforce small. Also, compilers were not very smart, and many programs were written in assembler, so it was considered a good thing to be able to write a program using few instructions. Instruction pipelines were simple, and processors grabbed one instruction at a time to execute it. The machinery inside the processor was quite complex anyway; decoding instructions was not felt to be much of a burden. \\nIn the 1970s, CPU and compiler designers realized that having such complex instructions was not so helpful after all. It was difficult to design processors in which those instructions were really efficient, and it was difficult to design compilers that really took advantage of these instructions. Chip area and compiler complexity was better spent on more generic pursuits such as more general-purpose registers. The Wikipedia article on RISC explains this in more detail.\\nMIPS is the ultimate RISC architecture, which is why it's taught so often.\\nThe x86 family is a bit different. It was originally a CISC architecture meant for systems with very small memory (no room for large instructions), and has undergone many successive versions. Today's x86 instruction set is not only complicated because it's CISC, but because it's really a 8088 with a 80386 with a Pentium possibly with an x86_64 processor.\\nIn today's world, RISC and CISC are no longer the black-and-white distinction they might have been once. Most CPU architectures have evolved to different shades of grey.\\nOn the RISC side, some modern MIPS variants have added multiplication and division instructions, with a non-uniform encoding. ARM processors have become more complex: many of them have a 16-bit instruction set called Thumb in addition to the âoriginalâ 32-bit instructions, not to mention Jazelle to execute JVM instructions on the CPU. Modern ARM processors also have SIMD instructions for multimedia applications: some complex instructions do pay after all.\\nOn the CISC side, all recent processors are to some extent RISC inside. They have microcode to define all these complex macro instructions. The sheer complexity of the processor makes the design of each model take several years, even with a RISC design, what with the large number of components, with pipelining and predictive execution and whatnot.\\nSo why do the fastest processors remain CISC outside? Part of it, in the case of the x86 (32-bit and 64-bit) family, is historical compatibility. But that's not the whole of it. In the early 2000s, Intel tried pushing the Itanium architecture. Itanium is an extreme case of complex instructions (not really CISC, though: its design has been dubbed EPIC). It even does away with the old-fashioned idea of executing instructions in sequence: all instructions are executed in parallel until the next barrier. One of the reasons Itanium didn't take is that nobody, whether at Intel or elsewhere, could write a decent compiler for it. Now a good old mostly-sequential processor like x86_64, that's something we understand.\"}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_lima['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
